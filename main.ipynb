{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import functools\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optiLib.problem import NetGraph\n",
    "from optiLib.problem import TaskGraph\n",
    "\n",
    "def generate_adjacency_matrix(rows, cols):\n",
    "    num_nodes = rows * cols\n",
    "    adjacency_matrix = [[0 for _ in range(num_nodes)] for _ in range(num_nodes)]\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            node_index = row * cols + col\n",
    "            if col > 0:  # узел слева\n",
    "                adjacency_matrix[node_index][node_index - 1] = 1\n",
    "            if col < cols - 1:  # узел справа\n",
    "                adjacency_matrix[node_index][node_index + 1] = 1\n",
    "            if row > 0:  # узел сверху\n",
    "                adjacency_matrix[node_index][node_index - cols] = 1\n",
    "            if row < rows - 1:  # узел снизу\n",
    "                adjacency_matrix[node_index][node_index + cols] = 1\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "martx = [\n",
    "    [0, 1000, 100, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "    [0, 0, 0, 0, 500, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "    [0, 0, 0, 0, 0, 100, 0, 0, 0, 0, 0, 0, 0], \n",
    "    [0, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0, 0, 0], \n",
    "    [0, 0, 0, 0, 0, 0, 0, 50, 0, 0, 0, 0, 0], \n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0], \n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 0, 0, 0], \n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 100, 0], \n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 0], \n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0], \n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50], \n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50], \n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "]\n",
    "\n",
    "net  = NetGraph(generate_adjacency_matrix(3, 3), net_power=(1000, 2500), net_power_arr=[5000, 500, 2000, 1000, 3000, 2000, 300, 1500, 1000], e0=(10, 50), emax=(70,100))\n",
    "task = TaskGraph(martx, w_arr=[500, 1000, 1000, 1000, 500, 500, 500, 200, 200, 200, 100, 100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "@functools.lru_cache\n",
    "def create_paths(vector, task_edges, network_graph):\n",
    "    RANDOM_SEED = 1\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    paths = {}\n",
    "    \n",
    "    for start, end in task_edges:\n",
    "        if vector[start] == vector[end]:\n",
    "            paths[str(start) + str(end)] = [vector[start]]\n",
    "        else:\n",
    "            paths[str(start) + str(end)] = random.choice(list(nx.all_shortest_paths(network_graph, vector[start], vector[end])))\n",
    "    return paths\n",
    "\n",
    "@functools.lru_cache\n",
    "def network_status_calculation(vector, problem):\n",
    "    RANDOM_SEED = 1\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    T_lim = problem.t_lim\n",
    "    vector_tuple = tuple(vector) \n",
    "    task_edges = tuple((start, end) for start, end, _ in nx.to_edgelist(problem.task_graph.graph))\n",
    "    network_graph = problem.network_graph.graph\n",
    "    \n",
    "    paths = create_paths(vector_tuple, task_edges, network_graph)\n",
    "    \n",
    "    net_number = network_graph.number_of_nodes()\n",
    "    task_number = problem.task_graph.graph.number_of_nodes()\n",
    "\n",
    "    W = [0] * net_number\n",
    "    v_task_to_node = [0] * net_number\n",
    "    v_sent_to_node = [0] * net_number\n",
    "    v_reseive_to_node = [0] * net_number\n",
    "    \n",
    "    for start, end, weight in nx.to_edgelist(problem.task_graph.graph):\n",
    "        path_key = str(start) + str(end)\n",
    "        path = paths[path_key]\n",
    "        \n",
    "        if len(path) > 1:\n",
    "            W[path[0]] += problem.task_graph.operations[start].w + weight['weight']\n",
    "            v_sent_to_node[path[0]] += weight['weight']\n",
    "            v_task_to_node[path[0]] += problem.task_graph.operations[start].w\n",
    "            \n",
    "            W[path[-1]] += problem.task_graph.operations[end].w + weight['weight']\n",
    "            v_reseive_to_node[path[-1]] += weight['weight']\n",
    "            v_task_to_node[path[-1]] += problem.task_graph.operations[end].w\n",
    "            \n",
    "            for node in path[1:-1]:\n",
    "                W[node] += 2 * weight['weight']\n",
    "                v_sent_to_node[node] += weight['weight']\n",
    "                v_reseive_to_node[node] += weight['weight']\n",
    "        else:\n",
    "            W[vector[start]] += problem.task_graph.operations[start].w\n",
    "            v_task_to_node[vector[start]] += problem.task_graph.operations[start].w\n",
    "            \n",
    "            W[vector[end]] += problem.task_graph.operations[end].w\n",
    "            v_task_to_node[vector[end]] += problem.task_graph.operations[end].w\n",
    "    \n",
    "    vector_tuple = tuple(vector) \n",
    "    \n",
    "    arr = sorted(nx.all_simple_paths(problem.task_graph.graph, 0, task_number - 1), key=len, reverse=True)\n",
    "    \n",
    "    T_task = [0] * task_number\n",
    "    len_first_path = len(arr[0])\n",
    "    time_per_task = T_lim / len_first_path\n",
    "    \n",
    "    for task in arr[0]:\n",
    "        T_task[task] = time_per_task\n",
    "    \n",
    "    for path_task in arr[1:]:\n",
    "        sum_t = sum(T_task[task] for task in path_task)\n",
    "        temp = [task for task in path_task if T_task[task] == 0]\n",
    "        \n",
    "        if temp:  # если нашлись задачи без оценки времени\n",
    "            time_remaining = max(0, T_lim - sum_t)\n",
    "            time_per_task_temp = time_remaining / len(temp)\n",
    "            for task in temp:\n",
    "                T_task[task] = time_per_task_temp\n",
    "    \n",
    "    T_NET = [0] * net_number\n",
    "\n",
    "    for start, end, _ in nx.to_edgelist(problem.task_graph.graph):\n",
    "        path_net = paths[str(start) + str(end)]\n",
    "        if len(path_net) == 1:\n",
    "            T_NET[path_net[-1]] = min(T_NET[path_net[-1]] or time_per_task, T_task[start], T_task[end])\n",
    "        else:\n",
    "            T_NET[path_net[-1]] = min(T_NET[path_net[-1]] or T_task[end], T_task[end])\n",
    "            time_start_share = T_task[start] / (len(path_net) - 1)\n",
    "            for node in path_net[:-1]:\n",
    "                T_NET[node] = min(T_NET[node] or time_start_share, time_start_share)\n",
    "    \n",
    "    special_t = T_lim / len_first_path\n",
    "    result = [[] for _ in range(net_number)]\n",
    "    for i, val in enumerate(vector):\n",
    "        result[val].append(i)\n",
    "    \n",
    "    for node in range(net_number):\n",
    "        common_tasks = set(result[node]) & set(arr[0])\n",
    "        if len(common_tasks) > 1:\n",
    "            T_NET[node] = special_t * len(common_tasks)\n",
    "    \n",
    "    D = [W[i] / (problem.network_graph.nodes[i].p * T_NET[i]) if T_NET[i] != 0 else 0 for i in range(net_number)]\n",
    "    return {\"w\":W, \"v_task_to_node\":v_task_to_node, \"v_sent_to_node\":v_sent_to_node, \"v_reseive_to_node\":v_reseive_to_node, \"D\":D, \"T_NET\":T_NET, \"T_task\":T_task}\n",
    "\n",
    "@functools.lru_cache\n",
    "def status(vector, problem):\n",
    "    problem.scheduler.calculate_schedule(vector)\n",
    "    return {\"Time\":problem.scheduler.get_total_execution_time(), \"edge_hop\":problem.scheduler.get_transfer_count(), \"time_node\":problem.scheduler.get_node_working_times()}\n",
    "\n",
    "def c1_time_limit(vector, problem):\n",
    "    \"\"\"\n",
    "    Проверка на ограничение по времени\n",
    "    \"\"\"\n",
    "    net_ststus = status(tuple(vector), problem)\n",
    "    time = net_ststus['Time']\n",
    "    return int(time <= problem.t_lim)\n",
    "\n",
    "def c2_restriction_first_node(vector, problem):\n",
    "    \"\"\"\n",
    "    Проверка на ограничение на первый узел \n",
    "    \"\"\"\n",
    "    net_ststus = status(tuple(vector), problem)\n",
    "    time_node = net_ststus['time_node']\n",
    "    return int(time_node[0] <= 1)\n",
    "\n",
    "def f1_min_hop(vector, problem):\n",
    "    net_ststus = status(tuple(vector), problem)\n",
    "    edge_hop = net_ststus['edge_hop']\n",
    "    return edge_hop\n",
    "\n",
    "def f_min_workload_node_0(vector, problem):\n",
    "    net_ststus = status(tuple(vector), problem)\n",
    "    t = net_ststus[\"Time\"]\n",
    "    time_node = net_ststus[\"time_node\"]\n",
    "\n",
    "    node = 0\n",
    "    workload = time_node.get(node, 0) / t\n",
    "    return 1 if workload == 0 else workload  \n",
    "\n",
    "\n",
    "def f_min_workload_node_1(vector, problem):\n",
    "    net_ststus = status(tuple(vector), problem)\n",
    "    t = net_ststus[\"Time\"]\n",
    "    time_node = net_ststus[\"time_node\"]\n",
    "    node = 1\n",
    "    workload = time_node.get(node, 0) / t\n",
    "    return 1 if workload == 0 else workload \n",
    "\n",
    "def f_min_workload_node_2(vector, problem):\n",
    "    net_ststus = status(tuple(vector), problem)\n",
    "    t = net_ststus[\"Time\"]\n",
    "    time_node = net_ststus[\"time_node\"]\n",
    "    node = 2\n",
    "    workload = time_node.get(node, 0) / t\n",
    "    return 1 if workload == 0 else workload \n",
    "\n",
    "def f_min_workload_node_3(vector, problem):\n",
    "    net_ststus = status(tuple(vector), problem)\n",
    "    t = net_ststus[\"Time\"]\n",
    "    time_node = net_ststus[\"time_node\"]\n",
    "    node = 3\n",
    "    workload = time_node.get(node, 0) / t\n",
    "    return 1 if workload == 0 else workload \n",
    "\n",
    "def f_min_workload_node_4(vector, problem):\n",
    "    net_ststus = status(tuple(vector), problem)\n",
    "    t = net_ststus[\"Time\"]\n",
    "    time_node = net_ststus[\"time_node\"]\n",
    "    node = 4\n",
    "    workload = time_node.get(node, 0) / t \n",
    "    return 1 if workload == 0 else workload \n",
    "\n",
    "def f_min_workload_node_5(vector, problem):\n",
    "    net_ststus = status(tuple(vector), problem)\n",
    "    t = net_ststus[\"Time\"]\n",
    "    time_node = net_ststus[\"time_node\"]\n",
    "    node = 5\n",
    "    workload = time_node.get(node, 0) / t\n",
    "    return 1 if workload == 0 else workload \n",
    "\n",
    "def f_min_workload_node_6(vector, problem):\n",
    "    net_ststus = status(tuple(vector), problem)\n",
    "    t = net_ststus[\"Time\"]\n",
    "    time_node = net_ststus[\"time_node\"]\n",
    "    node = 6\n",
    "    workload = time_node.get(node, 0) / t\n",
    "    return 1 if workload == 0 else workload \n",
    "\n",
    "def f_min_workload_node_7(vector, problem):\n",
    "    net_ststus = status(tuple(vector), problem)\n",
    "    t = net_ststus[\"Time\"]\n",
    "    time_node = net_ststus[\"time_node\"]\n",
    "    node = 7\n",
    "    workload = time_node.get(node, 0) / t\n",
    "    return 1 if workload == 0 else workload \n",
    "\n",
    "def f_min_workload_node_8(vector, problem):\n",
    "    net_ststus = status(tuple(vector), problem)\n",
    "    t = net_ststus[\"Time\"]\n",
    "    time_node = net_ststus[\"time_node\"]\n",
    "    node = 8\n",
    "    workload = time_node.get(node, 0) / t\n",
    "    return 1 if workload == 0 else workload \n",
    "\n",
    "def f2(vector, problem):\n",
    "    \"\"\"\n",
    "    Вычисляет количество пересылок данных, необходимых при распределении задач\n",
    "    по узлам сети, если изначально все задачи были на узле 0.\n",
    "    \n",
    "    Args:\n",
    "        vector (list): Вектор распределения задач на узлы сети.\n",
    "        problem (): network_graph (nx.Graph): Граф сети.\n",
    "        \n",
    "    Returns:\n",
    "        int: Общее количество пересылок данных.\n",
    "    \"\"\"\n",
    "    total_transfers = 0\n",
    "    network_graph = problem.network_graph.graph\n",
    "\n",
    "    for task_id, node_id in enumerate(vector):\n",
    "        if node_id != 0:\n",
    "            # Найти кратчайший путь от узла 0 до текущего узла\n",
    "            path = nx.shortest_path(network_graph, source=0, target=node_id)\n",
    "            \n",
    "            # Увеличить счетчик пересылок на количество узлов в пути\n",
    "            total_transfers += len(path) - 1\n",
    "    \n",
    "    return total_transfers + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optiLib import NetworkOptimizationProblem\n",
    "\n",
    "problem = NetworkOptimizationProblem(net, task, f_objective=[f1_min_hop, f_min_workload_node_0, f_min_workload_node_1, f_min_workload_node_2, f_min_workload_node_3, f_min_workload_node_4, f_min_workload_node_5, f_min_workload_node_6, f_min_workload_node_7, f_min_workload_node_8], f_constraints=[c1_time_limit, c2_restriction_first_node], t_lim=15, net_speed=100, bounds={0: [0,0]}, name=\"NETproblem_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эксперемент 7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее решение: [0 1 5 5 1 1 7 1 5 5 5 7 0]\n",
      "Значение целевой функции: 8.130076276834297e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for exp in range(0, 10001):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Эксперемент {exp}\")\n",
    "    RANDOM_SEED = exp\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    from optiLib.optimizers import RandomSearchOptimizer, ParticleSwarmOptimizer\n",
    "\n",
    "    # Инициализация оптимизатора\n",
    "    optimizer = ParticleSwarmOptimizer(problem, inertia = 1.7,cognitive = 2.5 , social = 1.5, num_particles=100, iterations=1000, update_history_coef = 1000)\n",
    "\n",
    "    # Запуск оптимизации\n",
    "    best_solution, best_value = optimizer.optimize()\n",
    "\n",
    "    from optiLib.helpers import print_solution\n",
    "    print_solution(best_solution, best_value)\n",
    "    if len(optimizer.history)>0:\n",
    "        optimizer.save(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optiLib import NetworkOptimizationProblem\n",
    "\n",
    "problem = NetworkOptimizationProblem(net, task, f_objective=[f1_min_hop, f_min_workload_node_0, f_min_workload_node_1, f_min_workload_node_2, f_min_workload_node_3, f_min_workload_node_4, f_min_workload_node_5, f_min_workload_node_6, f_min_workload_node_7, f_min_workload_node_8], f_constraints=[c1_time_limit, c2_restriction_first_node], t_lim=5, net_speed=5000, bounds={0: [0,0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for exp in range(0, 10001):\n",
    "    print(f\"Эксперемент {exp}\")\n",
    "    RANDOM_SEED = exp\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    from optiLib.optimizers import RandomSearchOptimizer, ParticleSwarmOptimizer\n",
    "\n",
    "    # Инициализация оптимизатора\n",
    "    optimizer = ParticleSwarmOptimizer(problem, inertia = 1.7,cognitive = 2.5 , social = 1.5, num_particles=100, iterations=1000, update_history_coef = 1000)\n",
    "\n",
    "    # Запуск оптимизации\n",
    "    best_solution, best_value = optimizer.optimize()\n",
    "\n",
    "    from optiLib.helpers import print_solution\n",
    "    print_solution(best_solution, best_value)\n",
    "    print(len(optimizer.history))\n",
    "    if len(optimizer.history)>0:\n",
    "        optimizer.save(exp)\n",
    "    \n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optiLib import NetworkOptimizationProblem\n",
    "\n",
    "problem = NetworkOptimizationProblem(net, task, f_objective=[f1_min_hop, f_min_workload_node_0, f_min_workload_node_1, f_min_workload_node_2, f_min_workload_node_3, f_min_workload_node_4, f_min_workload_node_5, f_min_workload_node_6, f_min_workload_node_7, f_min_workload_node_8], f_constraints=[c1_time_limit, c2_restriction_first_node], t_lim=5, net_speed=5000, bounds={0: [0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for exp in range(0, 10001):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Эксперемент {exp}\")\n",
    "    RANDOM_SEED = exp\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    from optiLib.optimizers import RandomSearchOptimizer\n",
    "\n",
    "    # Инициализация оптимизатора\n",
    "    optimizer = RandomSearchOptimizer(problem, iterations=300000, update_history_coef = 1000)\n",
    "\n",
    "    # Запуск оптимизации\n",
    "    best_solution, best_value = optimizer.optimize()\n",
    "\n",
    "    from optiLib.helpers import print_solution\n",
    "    print_solution(best_solution, best_value)\n",
    "    if len(optimizer.history)>0:\n",
    "        optimizer.save(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optiLib import NetworkOptimizationProblem\n",
    "\n",
    "problem = NetworkOptimizationProblem(net, task, f_objective=[f1_min_hop, f_min_workload_node_0, f_min_workload_node_1, f_min_workload_node_2, f_min_workload_node_3, f_min_workload_node_4, f_min_workload_node_5, f_min_workload_node_6, f_min_workload_node_7, f_min_workload_node_8], f_constraints=[c1_time_limit, c2_restriction_first_node], t_lim=5, net_speed=5000, bounds={0: [0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for exp in range(0, 10001):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Эксперемент {exp}\")\n",
    "    RANDOM_SEED = exp\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    from optiLib.optimizers import DirectedRandomSearchOptimizer\n",
    "\n",
    "    # Инициализация оптимизатора\n",
    "    optimizer = DirectedRandomSearchOptimizer(problem, iterations=300000, update_history_coef = 1000)\n",
    "\n",
    "    # Запуск оптимизации\n",
    "    best_solution, best_value = optimizer.optimize()\n",
    "\n",
    "    from optiLib.helpers import print_solution\n",
    "    print_solution(best_solution, best_value)\n",
    "    if len(optimizer.history)>0:\n",
    "        optimizer.save(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optiLib import NetworkOptimizationProblem\n",
    "\n",
    "problem = NetworkOptimizationProblem(net, task, f_objective=[f1_min_hop, f_min_workload_node_0, f_min_workload_node_1, f_min_workload_node_2, f_min_workload_node_3, f_min_workload_node_4, f_min_workload_node_5, f_min_workload_node_6, f_min_workload_node_7, f_min_workload_node_8], f_constraints=[c1_time_limit, c2_restriction_first_node], t_lim=5, net_speed=5000, bounds={0: [0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for exp in range(0, 10001):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Эксперемент {exp}\")\n",
    "    RANDOM_SEED = exp\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    from optiLib.optimizers import GeneticAlgorithm\n",
    "\n",
    "    # Инициализация оптимизатора\n",
    "    optimizer = GeneticAlgorithm(problem, population_size=100, generations=1000, update_history_coef = 1000)\n",
    "\n",
    "    # Запуск оптимизации\n",
    "    best_solution, best_value = optimizer.optimize()\n",
    "\n",
    "    from optiLib.helpers import print_solution\n",
    "    print_solution(best_solution, best_value)\n",
    "    if len(optimizer.history)>0:\n",
    "        optimizer.save(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.scheduler.calculate_schedule([0, 0, 4, 0, 3, 8, 4, 8, 8, 8, 8, 2, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.scheduler.print_extended_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.scheduler.create_gantt_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.evaluate([0,2,2,2,1,1,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status(tuple([0,8,5,2,1,1,0,0,7,0,0,0,8]), problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "from optiLib.optimizers import RandomSearchOptimizer\n",
    "\n",
    "# Инициализация оптимизатора\n",
    "optimizer = RandomSearchOptimizer(problem,iterations = 1000)\n",
    "\n",
    "# Запуск оптимизации\n",
    "best_solution, best_value = optimizer.optimize()\n",
    "\n",
    "from optiLib.helpers import print_solution\n",
    "print_solution(best_solution, best_value)\n",
    "\n",
    "for i, item in enumerate(optimizer.history):\n",
    "    optimizer.history[i]={**item, **network_status_calculation(tuple(item['vector']), problem)}\n",
    "\n",
    "optimizer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "from optiLib.optimizers import GreedyOptimizer\n",
    "\n",
    "# Инициализация оптимизатора\n",
    "optimizer = GreedyOptimizer(problem)\n",
    "\n",
    "# Запуск оптимизации\n",
    "best_solution, best_value = optimizer.optimize()\n",
    "\n",
    "from optiLib.helpers import print_solution\n",
    "print_solution(best_solution, best_value)\n",
    "\n",
    "for i, item in enumerate(optimizer.history):\n",
    "    optimizer.history[i]={**item, **network_status_calculation(tuple(item['vector']), problem)}\n",
    "\n",
    "optimizer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
